import argparse
import asyncio
import logging
import math

import os
import cv2
import numpy
from av import VideoFrame

from aiortc import (
    RTCIceCandidate,
    RTCPeerConnection,
    RTCSessionDescription,
    VideoStreamTrack,
)
from aiortc.contrib.media import MediaBlackhole, MediaPlayer, MediaRecorder, generator_type
from aiortc.contrib.signaling import BYE, add_signaling_arguments, create_signaling


class FlagVideoStreamTrack(VideoStreamTrack):
    """
    A video track that returns an animated flag.
    """

    def __init__(self):
        super().__init__()  # don't forget this!
        self.counter = 0
        height, width = 480, 640

        # generate flag
        data_bgr = numpy.hstack(
            [
                self._create_rectangle(
                    width=213, height=480, color=(255, 0, 0)
                ),  # blue
                self._create_rectangle(
                    width=214, height=480, color=(255, 255, 255)
                ),  # white
                self._create_rectangle(width=213, height=480, color=(0, 0, 255)),  # red
            ]
        )

        # shrink and center it
        M = numpy.float32([[0.5, 0, width / 4], [0, 0.5, height / 4]])
        data_bgr = cv2.warpAffine(data_bgr, M, (width, height))

        # compute animation
        omega = 2 * math.pi / height
        id_x = numpy.tile(numpy.array(range(width), dtype=numpy.float32), (height, 1))
        id_y = numpy.tile(
            numpy.array(range(height), dtype=numpy.float32), (width, 1)
        ).transpose()

        self.frames = []
        for k in range(30):
            phase = 2 * k * math.pi / 30
            map_x = id_x + 10 * numpy.cos(omega * id_x + phase)
            map_y = id_y + 10 * numpy.sin(omega * id_x + phase)
            self.frames.append(
                VideoFrame.from_ndarray(
                    cv2.remap(data_bgr, map_x, map_y, cv2.INTER_LINEAR), format="bgr24"
                )
            )

    async def recv(self):
        pts, time_base = await self.next_timestamp()

        frame = self.frames[self.counter % 30]
        frame.pts = pts
        frame.time_base = time_base
        self.counter += 1
        return frame

    def _create_rectangle(self, width, height, color):
        data_bgr = numpy.zeros((height, width, 3), numpy.uint8)
        data_bgr[:, :] = color
        return data_bgr


async def run(pc, player, recorder, signaling, role, quantizer=32, lr_quantizer=32, lr_target_bitrate=100000, lr_enable_gcc=False):
    def add_tracks():
        if player and player.audio:
            pc.addTrack(player.audio)

        if player and player.video:
            pc.addTrack(player.video, quantizer)
        elif generator_type not in ['bicubic', 'swinir-lte']:
            """do not use a high-res video stream,
                use only a low-res stream
            """
            pc.addTrack(FlagVideoStreamTrack())

        if player and player.keypoints:
            pc.addTrack(player.keypoints)

        if player and player.lr_video:
            pc.addTrack(player.lr_video, lr_quantizer, lr_target_bitrate, lr_enable_gcc)

    @pc.on("track")
    def on_track(track):
        print("Receiving %s" % track.kind)
        recorder.addTrack(track)

    # connect signaling
    await signaling.connect()

    if role == "offer":
        # send offer
        add_tracks()
        await pc.setLocalDescription(await pc.createOffer())
        await signaling.send(pc.localDescription)

    # consume signaling
    while True:
        obj = await signaling.receive()

        if isinstance(obj, RTCSessionDescription):
            await pc.setRemoteDescription(obj)
            await recorder.start()

            if obj.type == "offer":
                # send answer
                add_tracks()
                await pc.setLocalDescription(await pc.createAnswer())
                await signaling.send(pc.localDescription)
        elif isinstance(obj, RTCIceCandidate):
            await pc.addIceCandidate(obj)
        elif obj is BYE:
            print("Exiting")
            break


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Video stream from the command line")
    parser.add_argument("role", choices=["offer", "answer"])
    parser.add_argument("--play-from", help="Read the media from a file and sent it."),
    parser.add_argument("--record-to", help="Write received media to a file."),
    parser.add_argument("--verbose", "-v", action="count")
    parser.add_argument("--fps", type=int, help="fps you want to sample at")
    parser.add_argument("--save-dir", type=str, help="folder to save frames + latency data in")
    parser.add_argument('--enable-prediction', action='store_true')
    parser.add_argument('--prediction-type', type=str, default="keypoints",
                        help="indicate to use_low_res_video or keypoints or bicubic")
    parser.add_argument("--output-fps", type=int, default=30,
                        help="fps you want to save the video with")
    parser.add_argument("--quantizer", type=int, default=32,
                        help="quantizer to compress video stream with")
    parser.add_argument("--lr-quantizer", type=int, default=32,
                        help="quantizer to compress low-res video stream with")
    parser.add_argument("--lr-target-bitrate", type=int, default=100000,
                        help="target bitrate for low-res video stream (bps)")
    parser.add_argument("--lr-enable-gcc", action='store_true',
                        help="enable gcc to control low-res video stream's bitrate")
    parser.add_argument("--reference-update-freq", type=int, default=30,
                        help="the frequency that the reference frame is updated")

    add_signaling_arguments(parser)
    args = parser.parse_args()

    if args.verbose:
        logging.basicConfig(level=logging.DEBUG)

    # create signaling and peer connection
    signaling = create_signaling(args)
    pc = RTCPeerConnection()

    # create save directory
    if args.save_dir is not None:
        if not os.path.exists(args.save_dir):
            os.makedirs(args.save_dir)

    # create media source
    if args.play_from:
        player = MediaPlayer(args.play_from, args.enable_prediction, args.prediction_type,
                             args.reference_update_freq, args.fps, args.save_dir)
    else:
        player = None

    # create media sink
    if args.record_to:
        recorder = MediaRecorder(args.record_to, enable_prediction=args.enable_prediction, \
                                prediction_type=args.prediction_type, \
                                reference_update_freq=args.reference_update_freq, \
                                output_fps=args.output_fps, save_dir=args.save_dir)
    else:
        recorder = MediaBlackhole()

    # run event loop
    loop = asyncio.get_event_loop()
    try:
        loop.run_until_complete(
            run(
                pc=pc,
                player=player,
                recorder=recorder,
                signaling=signaling,
                role=args.role,
                quantizer=args.quantizer,
                lr_quantizer=args.lr_quantizer,
                lr_target_bitrate=args.lr_target_bitrate,
                lr_enable_gcc=args.lr_enable_gcc
            )
        )
    except KeyboardInterrupt:
        pass
    finally:
        # cleanup
        loop.run_until_complete(recorder.stop())
        loop.run_until_complete(signaling.close())
        loop.run_until_complete(pc.close())
